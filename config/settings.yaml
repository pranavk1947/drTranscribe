transcription:
  provider: "groq"              # Options: "groq", "gemini", "openai", "azure", "mock"
  model: "whisper-large-v3"     # For groq: "whisper-large-v3", for gemini: "gemini-2.0-flash"
  output_format: "wav"          # Format to send to provider: "wav" or "webm"

extraction:
  provider: "gemini"
  model: "gemini-1.5-flash"
  temperature: 0.3

# OpenAI Configuration
openai:
  api_key: "${OPENAI_API_KEY}"

# Groq Configuration (FREE!)
groq:
  api_key: "${GROQ_API_KEY}"

# Google Gemini Configuration
gemini:
  api_key: "${GEMINI_API_KEY}"

# Claude (Anthropic) Configuration
claude:
  api_key: "${CLAUDE_API_KEY}"

# Azure OpenAI Configuration
azure_openai:
  api_key: "${AZURE_OPENAI_API_KEY}"
  endpoint: "https://llmproxyhub5196723659.cognitiveservices.azure.com/"
  api_version: "2024-08-01-preview"
  whisper_deployment: "whisper"
  gpt_deployment: "gpt-4.1-mini"

server:
  host: "0.0.0.0"
  port: 8000

audio:
  chunk_duration_seconds: 6  # Duration of each audio chunk for real-time transcription
  sample_rate: 16000         # Groq Whisper optimized sample rate (16kHz)
  channels: 1                # Mono channel (required for medical clarity)

# Chrome Extension Configuration (documentation only - no backend changes needed)
# The extension connects to the same WebSocket endpoint and uses the same protocol.
# Load from: chrome://extensions/ -> Developer mode -> Load unpacked -> chromeExtension/
chrome_extension:
  enabled: true  # Extension uses the same /ws and /api/config endpoints
